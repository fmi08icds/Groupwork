{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 2090)\n"
     ]
    }
   ],
   "source": [
    "# read in single test image\n",
    "img = cv.imread(\"/home/leo/Documents/UNI/ICDS/Groupwork/Group1/data/test/normal/IM-0115-0001.jpeg\", cv.IMREAD_GRAYSCALE)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_layer:\n",
    "    \"\"\"\n",
    "    Convolution layer expects an input dimension (in_dim) of shape (h, w, d), where h and w\n",
    "    are hight and width of images and d the number of dimensions. \n",
    "\n",
    "    Currently there is no padding or stride configuration. The layer operates with no paddling \n",
    "    and a stride of one.\n",
    "\n",
    "    in_dim -> tuple of shape (h,w,d) -> input image dimensions \n",
    "    conv_size -> tuple of shape (h, w) -> size of convolution kernel\n",
    "    kernel_num -> int -> number of kernels\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, conv_size=(3,3), kernel_num=4, debug = False):\n",
    "        self.kernel_num = kernel_num\n",
    "        self.conv_size = conv_size\n",
    "        self.conv_kernels = [None] * self.kernel_num\n",
    "\n",
    "        for i in range(0, self.kernel_num):\n",
    "            if debug:\n",
    "                self.conv_kernels[i] = self.debug_conv((conv_size[0], conv_size[1], in_dim[2]))\n",
    "            else:\n",
    "                self.conv_kernels[i] = np.random.uniform(-1,1,(conv_size[0], conv_size[1], in_dim[2]))\n",
    "\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = (self.in_dim[0] - (conv_size[0] - 1), self.in_dim[1] - (self.conv_size[1] - 1), self.kernel_num)\n",
    "    \n",
    "    '''\n",
    "    perform a forward convolution on the specified image.\n",
    "\n",
    "    img -> np.array of shape (h,w,d)\n",
    "    \n",
    "    ret:\n",
    "    out_img -> np.array of shape (h,w,d)\n",
    "    '''\n",
    "    def forward(self, img):\n",
    "        out_img = np.zeros(self.out_dim)\n",
    "        for k in range(0, self.kernel_num):\n",
    "            for h in range(0, self.out_dim[0]):\n",
    "                for w in range(0, self.out_dim[1]):\n",
    "                    out_img[h, w, k] = np.sum(img[h:h+self.conv_size[0], w:w+self.conv_size[1],:] * self.conv_kernels[k])\n",
    "        return out_img\n",
    "    \n",
    "    '''\n",
    "    get out put dimension of this network layer\n",
    "\n",
    "    ret:\n",
    "    out_dim -> tuple of shape (h,w,d)\n",
    "    '''\n",
    "    def get_out_dim(self):\n",
    "        return self.out_dim\n",
    "    \n",
    "    def debug_conv(self, size):\n",
    "        kernel = np.zeros(size)\n",
    "        for i in range(0, size[0],2):\n",
    "            kernel[i,:,:] = 1\n",
    "        return kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before conv\n",
      "[[1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 1. 1. 1. 1. 1.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "[[1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 1. 0.]]\n",
      "expected out dim\n",
      "(4, 4, 3)\n",
      "output conv shape\n",
      "(4, 4, 3)\n",
      "output conv\n",
      "[[0.46422625 0.51825788 0.46422625 0.51825788]\n",
      " [0.26437059 0.31840223 0.26437059 0.31840223]\n",
      " [0.46422625 0.51825788 0.46422625 0.51825788]\n",
      " [0.26437059 0.31840223 0.26437059 0.31840223]]\n"
     ]
    }
   ],
   "source": [
    "# test conv layer\n",
    "a = np.zeros((6,6,2))\n",
    "for w in range(0,a.shape[0], 2):\n",
    "    for h in range(0,a.shape[1]):\n",
    "        a[w, h, 0] = 1\n",
    "\n",
    "for w in range(0,a.shape[0]):\n",
    "    for h in range(0,a.shape[1], 2):\n",
    "        a[w, h, 1] = 1\n",
    "\n",
    "print(\"input before conv\")\n",
    "print(a[:,:,0])\n",
    "print(a[:,:,1])\n",
    "c = conv_layer(in_dim=a.shape, conv_size=(3,3), kernel_num=3)\n",
    "print(\"expected out dim\")\n",
    "print(c.get_out_dim())\n",
    "d = c.forward(a)\n",
    "print(\"output conv shape\")\n",
    "print(d.shape)\n",
    "print(\"output conv\")\n",
    "print(d[:,:,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pooling_layer:\n",
    "    \"\"\"\n",
    "    Max pooling layer expects an input dimension (in_dim) of shape (h, w, d), where h and w\n",
    "    are hight and width of images and d the number of dimensions. \n",
    "    \n",
    "    Currently there is no padding or stride configuration. The layer operates with no paddling \n",
    "    and a stride of one.\n",
    "\n",
    "    in_dim -> tuple of shape (h,w,d) -> input image dimensions \n",
    "    pooling_size -> tuple of shape (h, w) -> size of pooling filter\n",
    "    \"\"\"\n",
    "    def __init__(self, in_dim, pooling_size=(3,3)):\n",
    "        self.pooling_size = pooling_size\n",
    "        self.in_dim = in_dim\n",
    "        h_overflow = 1 if self.in_dim[0] % self.pooling_size[0] > 0 else 0\n",
    "        w_overflow = 1 if self.in_dim[1] % self.pooling_size[1] > 0 else 0\n",
    "        self.out_dim = (int(self.in_dim[0] / self.pooling_size[0]) + h_overflow, int(self.in_dim[0] / self.pooling_size[0]) + w_overflow, self.in_dim[2])\n",
    "        \n",
    "    '''\n",
    "    perform forward pooling on the specified image.\n",
    "\n",
    "    img -> np.array of shape (h,w,d)\n",
    "    \n",
    "    ret:\n",
    "    out_img -> np.array of shape (h,w,d)\n",
    "    '''\n",
    "    def forward(self, img):\n",
    "        out_img = np.empty(self.out_dim)\n",
    "        h_overflow = True if self.in_dim[0] / self.pooling_size[0] - self.out_dim[0] > 0 else False\n",
    "        w_overflow = True if self.in_dim[1] / self.pooling_size[1] - self.out_dim[1] > 0 else False\n",
    "        for d in range(0, self.out_dim[2]):\n",
    "            for w in range(0, self.out_dim[0]):\n",
    "                for h in range(0, self.out_dim[1]):\n",
    "                    pool_size_h = self.pooling_size[0]\n",
    "                    pool_size_w = self.pooling_size[1]\n",
    "                    if h_overflow and h == (self.out_dim[0]-1):\n",
    "                        pool_size_h = self.in_dim[0] % self.pooling_size[0]\n",
    "                    if h_overflow and h == (self.out_dim[0]-1):\n",
    "                        pool_size_w = self.in_dim[1] % self.pooling_size[1]\n",
    "\n",
    "                    out_img[h,w,d] = np.max(img[h*pool_size_h:h*pool_size_h+pool_size_h, w*pool_size_w:w*pool_size_w+pool_size_w,d])\n",
    "        return out_img\n",
    "    '''\n",
    "    get out put dimension of this network layer\n",
    "\n",
    "    ret:\n",
    "    out_dim -> tuple of shape (h,w,d)\n",
    "    '''\n",
    "    def get_out_dim(self):\n",
    "        return self.out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before pool\n",
      "[[ 0.  1.  2.  3.  4.  5.  6.]\n",
      " [ 7.  8.  9. 10. 11. 12. 13.]\n",
      " [14. 15. 16. 17. 18. 19. 20.]\n",
      " [21. 22. 23. 24. 25. 26. 27.]\n",
      " [28. 29. 30. 31. 32. 33. 34.]\n",
      " [35. 36. 37. 38. 39. 40. 41.]\n",
      " [42. 43. 44. 45. 46. 47. 48.]]\n",
      "output pool\n",
      "[[16. 19. 20.]\n",
      " [37. 40. 41.]\n",
      " [44. 47. 48.]]\n"
     ]
    }
   ],
   "source": [
    "# test pool layer\n",
    "a = np.zeros((7, 7, 3))\n",
    "index = 0\n",
    "for w in range(0,a.shape[0]):\n",
    "    for h in range(0,a.shape[1]):\n",
    "        a[w,h,:] = index\n",
    "        index += 1\n",
    "print(\"input before pool\")\n",
    "print(a[:,:,0])\n",
    "c = max_pooling_layer(in_dim=a.shape, pooling_size=(3,3))\n",
    "d = c.forward(a)\n",
    "print(\"output pool\")\n",
    "print(d[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently only ReLU activation function hardcoded\n",
    "class activation_layer:\n",
    "    '''\n",
    "    ReLU activation layer performs a ReLU function on each element in the input image. \n",
    "    This means it basically set everything to zero that is smaller then zero.\n",
    "\n",
    "    in_dim -> tuple of shape (h,w,d) -> input image dimensions \n",
    "    '''\n",
    "    def __init__(self, in_dim,):\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def forward(self, img):\n",
    "        out_img = np.stack(np.vectorize(self.relu)(img), axis=0)\n",
    "        return out_img\n",
    "\n",
    "    def relu(self, el):\n",
    "        return(np.maximum(0, el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before activation\n",
      "[[[-4. -3. -2.]\n",
      "  [-1.  0.  1.]\n",
      "  [ 2.  3.  4.]]\n",
      "\n",
      " [[-4. -3. -2.]\n",
      "  [-1.  0.  1.]\n",
      "  [ 2.  3.  4.]]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [2. 3. 4.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [2. 3. 4.]]]\n"
     ]
    }
   ],
   "source": [
    "# test activation layer\n",
    "a = np.zeros((2, 3, 3))\n",
    "index = -4\n",
    "for k in range(0,a.shape[1]):\n",
    "    for h in range(0,a.shape[2]):\n",
    "        a[:, k, h] = index\n",
    "        index += 1\n",
    "print(\"input before activation\")\n",
    "print(a)\n",
    "r = activation_layer(a.shape)\n",
    "b = r.forward(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fully_connected_layer:\n",
    "    '''\n",
    "    The fully connected layer transforms the input into a fully connected network\n",
    "    with an output vector of out_dim.\n",
    "\n",
    "    in_dim -> tuple of shape (h,w,d) -> input image dimensions \n",
    "    out_dim -> int -> defines the number of output nodes\n",
    "    '''\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        w_dim = 1\n",
    "        for d in in_dim:\n",
    "            w_dim = w_dim * d\n",
    "        self.weights = np.ones((self.out_dim, w_dim))\n",
    "    \n",
    "    \n",
    "    def forward(self, img):\n",
    "        out_vec = np.zeros(self.out_dim)\n",
    "        img_vec = img.flatten()\n",
    "\n",
    "        for i in range(0, self.out_dim):\n",
    "            out_vec[i] = np.sum(img_vec * self.weights[i])\n",
    "        return out_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before fully connected\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "output pool\n",
      "[18. 18. 18.]\n"
     ]
    }
   ],
   "source": [
    "# test fully connected layer\n",
    "a = np.ones((2, 3, 3))\n",
    "\n",
    "print(\"input before fully connected\")\n",
    "print(a)\n",
    "c = fully_connected_layer(in_dim=a.shape, out_dim=3)\n",
    "d = c.forward(a)\n",
    "print(\"output pool\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cnn\n",
      "[[[ 0.]\n",
      "  [ 1.]\n",
      "  [ 2.]\n",
      "  [ 3.]\n",
      "  [ 4.]\n",
      "  [ 5.]]\n",
      "\n",
      " [[ 6.]\n",
      "  [ 7.]\n",
      "  [ 8.]\n",
      "  [ 9.]\n",
      "  [10.]\n",
      "  [11.]]\n",
      "\n",
      " [[12.]\n",
      "  [13.]\n",
      "  [14.]\n",
      "  [15.]\n",
      "  [16.]\n",
      "  [17.]]\n",
      "\n",
      " [[18.]\n",
      "  [19.]\n",
      "  [20.]\n",
      "  [21.]\n",
      "  [22.]\n",
      "  [23.]]\n",
      "\n",
      " [[24.]\n",
      "  [25.]\n",
      "  [26.]\n",
      "  [27.]\n",
      "  [28.]\n",
      "  [29.]]\n",
      "\n",
      " [[30.]\n",
      "  [31.]\n",
      "  [32.]\n",
      "  [33.]\n",
      "  [34.]\n",
      "  [35.]]]\n",
      "after conv\n",
      "[[[ -29.73879441   10.04431367]\n",
      "  [ -33.16698165   12.38302338]\n",
      "  [ -36.5951689    14.72173309]\n",
      "  [ -40.02335614   17.06044281]]\n",
      "\n",
      " [[ -50.30791788   24.07657195]\n",
      "  [ -53.73610513   26.41528166]\n",
      "  [ -57.16429237   28.75399137]\n",
      "  [ -60.59247962   31.09270108]]\n",
      "\n",
      " [[ -70.87704135   38.10883022]\n",
      "  [ -74.3052286    40.44753993]\n",
      "  [ -77.73341584   42.78624965]\n",
      "  [ -81.16160309   45.12495936]]\n",
      "\n",
      " [[ -91.44616483   52.1410885 ]\n",
      "  [ -94.87435207   54.47979821]\n",
      "  [ -98.30253932   56.81850792]\n",
      "  [-101.73072656   59.15721764]]]\n",
      "after activation\n",
      "[[[ 0.         10.04431367]\n",
      "  [ 0.         12.38302338]\n",
      "  [ 0.         14.72173309]\n",
      "  [ 0.         17.06044281]]\n",
      "\n",
      " [[ 0.         24.07657195]\n",
      "  [ 0.         26.41528166]\n",
      "  [ 0.         28.75399137]\n",
      "  [ 0.         31.09270108]]\n",
      "\n",
      " [[ 0.         38.10883022]\n",
      "  [ 0.         40.44753993]\n",
      "  [ 0.         42.78624965]\n",
      "  [ 0.         45.12495936]]\n",
      "\n",
      " [[ 0.         52.1410885 ]\n",
      "  [ 0.         54.47979821]\n",
      "  [ 0.         56.81850792]\n",
      "  [ 0.         59.15721764]]]\n",
      "after pooling\n",
      "[[[ 0.         42.78624965]\n",
      "  [ 0.         45.12495936]]\n",
      "\n",
      " [[ 0.         56.81850792]\n",
      "  [ 0.         59.15721764]]]\n",
      "after fully connected\n",
      "[203.88693457 203.88693457]\n"
     ]
    }
   ],
   "source": [
    "# test them in succession\n",
    "\n",
    "img = np.ones((6, 6, 1))\n",
    "index = 0\n",
    "for k in range(0,img.shape[0]):\n",
    "    for h in range(0,img.shape[1]):\n",
    "        img[k, h] = index\n",
    "        index += 1\n",
    "\n",
    "c1 = conv_layer(in_dim=img.shape, conv_size=(3,3), kernel_num=2)\n",
    "a1 = activation_layer(in_dim=c1.get_out_dim())\n",
    "p1 = max_pooling_layer(in_dim=c1.get_out_dim(), pooling_size=(3,3))\n",
    "f1 = fully_connected_layer(in_dim=p1.get_out_dim(), out_dim=2)\n",
    "print(\"before cnn\")\n",
    "print(img)\n",
    "k = c1.forward(img)\n",
    "print(\"after conv\")\n",
    "print(k)\n",
    "k = a1.forward(k)\n",
    "print(\"after activation\")\n",
    "print(k)\n",
    "k = p1.forward(k)\n",
    "print(\"after pooling\")\n",
    "print(k)\n",
    "k = f1.forward(k)\n",
    "print(\"after fully connected\")\n",
    "print(k)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

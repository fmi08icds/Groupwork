{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1858, 2090)\n"
     ]
    }
   ],
   "source": [
    "# read in single test image\n",
    "img = cv.imread(\"/home/leo/Documents/UNI/ICDS/Groupwork/Group1/data/test/normal/IM-0115-0001.jpeg\", cv.IMREAD_GRAYSCALE)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_layer:\n",
    "    def __init__(self, in_dim, conv_size=(3,3), conv_num=4):\n",
    "        self.conv_size = conv_size\n",
    "        self.conv_num = conv_num\n",
    "        self.conv_kernels = [None] * self.conv_num\n",
    "        for i in range(0, self.conv_num):\n",
    "            self.conv_kernels[i] = np.empty(conv_size)\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = ( self.conv_num, self.in_dim[0] - (conv_size[0] - 1), self.in_dim[1] - (self.conv_size[1] - 1))\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out_img = np.zeros(self.out_dim)\n",
    "        for i in range(0, self.conv_num):\n",
    "            for ii in range(0, self.out_dim[1]):\n",
    "                for iii in range(0, self.out_dim[2]):\n",
    "                    out_img[i, ii, iii] = np.sum(img[ii:ii+self.conv_size[0], iii:iii+self.conv_size[1]] * self.conv_kernels[i])\n",
    "        return out_img\n",
    "    \n",
    "    def get_out_dim(self):\n",
    "        return self.out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before conv\n",
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]\n",
      " [18. 19. 20. 21. 22. 23.]\n",
      " [24. 25. 26. 27. 28. 29.]\n",
      " [30. 31. 32. 33. 34. 35.]]\n",
      "expected out dim\n",
      "(3, 4, 4)\n",
      "output conv shape\n",
      "(3, 4, 4)\n",
      "output conv\n",
      "[[[  1320.   1482.   1644.   1806.]\n",
      "  [  2292.   2454.   2616.   2778.]\n",
      "  [  3264.   3426.   3588.   3750.]\n",
      "  [  4236.   4398.   4560.   4722.]]\n",
      "\n",
      " [[ 42258.  46980.  51702.  56424.]\n",
      "  [ 70590.  75312.  80034.  84756.]\n",
      "  [ 98922. 103644. 108366. 113088.]\n",
      "  [127254. 131976. 136698. 141420.]]\n",
      "\n",
      " [[  1320.   1482.   1644.   1806.]\n",
      "  [  2292.   2454.   2616.   2778.]\n",
      "  [  3264.   3426.   3588.   3750.]\n",
      "  [  4236.   4398.   4560.   4722.]]]\n"
     ]
    }
   ],
   "source": [
    "# test conv layer\n",
    "a = np.zeros((6,6))\n",
    "index = 0\n",
    "for i in range(0,a.shape[0]):\n",
    "    for ii in range(0,a.shape[1]):\n",
    "        a[i, ii] = index\n",
    "        index += 1\n",
    "\n",
    "print(\"input before conv\")\n",
    "print(a)\n",
    "c = conv_layer(in_dim=a.shape, conv_size=(3,3), conv_num=3)\n",
    "print(\"expected out dim\")\n",
    "print(c.get_out_dim())\n",
    "d = c.forward(a)\n",
    "print(\"output conv shape\")\n",
    "print(d.shape)\n",
    "print(\"output conv\")\n",
    "print(d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class max_pooling_layer:\n",
    "    def __init__(self, in_dim, pooling_size=(3,3)):\n",
    "        self.pooling_size = pooling_size\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = (self.in_dim[0], self.in_dim[1] - (self.pooling_size[0] - 1), self.in_dim[2] - (self.pooling_size[1] - 1))\n",
    "        \n",
    "    def forward(self, img):\n",
    "        out_img = np.empty(self.out_dim)\n",
    "        \n",
    "        for i in range(0, self.out_dim[0]):\n",
    "            for ii in range(0, self.out_dim[1]):\n",
    "                for iii in range(0, self.out_dim[2]):\n",
    "                    out_img[i,ii,iii] = np.max(img[i, ii:ii+self.pooling_size[0], iii:iii+self.pooling_size[1]])\n",
    "        return out_img\n",
    "    \n",
    "    def get_out_dim(self):\n",
    "        return self.out_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before pool\n",
      "[[[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]\n",
      "  [10. 11. 12. 13. 14.]\n",
      "  [15. 16. 17. 18. 19.]\n",
      "  [20. 21. 22. 23. 24.]]\n",
      "\n",
      " [[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]\n",
      "  [10. 11. 12. 13. 14.]\n",
      "  [15. 16. 17. 18. 19.]\n",
      "  [20. 21. 22. 23. 24.]]\n",
      "\n",
      " [[ 0.  1.  2.  3.  4.]\n",
      "  [ 5.  6.  7.  8.  9.]\n",
      "  [10. 11. 12. 13. 14.]\n",
      "  [15. 16. 17. 18. 19.]\n",
      "  [20. 21. 22. 23. 24.]]]\n",
      "output pool\n",
      "[[[12. 13. 14.]\n",
      "  [17. 18. 19.]\n",
      "  [22. 23. 24.]]\n",
      "\n",
      " [[12. 13. 14.]\n",
      "  [17. 18. 19.]\n",
      "  [22. 23. 24.]]\n",
      "\n",
      " [[12. 13. 14.]\n",
      "  [17. 18. 19.]\n",
      "  [22. 23. 24.]]]\n"
     ]
    }
   ],
   "source": [
    "# test pool layer\n",
    "a = np.zeros((3, 5, 5))\n",
    "index = 0\n",
    "for i in range(0,a.shape[1]):\n",
    "    for ii in range(0,a.shape[2]):\n",
    "        a[:, i, ii] = index\n",
    "        index += 1\n",
    "print(\"input before pool\")\n",
    "print(a)\n",
    "c = max_pooling_layer(in_dim=a.shape, pooling_size=(3,3))\n",
    "d = c.forward(a)\n",
    "print(\"output pool\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# currently only ReLU activation function hardcoded\n",
    "class activation_layer:\n",
    "    def __init__(self, in_dim):\n",
    "        self.in_dim = in_dim\n",
    "\n",
    "    def forward(self, img):\n",
    "        out_img = np.stack(np.vectorize(self.relu)(img), axis=0)\n",
    "        return out_img\n",
    "\n",
    "    def relu(self, el):\n",
    "        return(np.maximum(0, el))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before activation\n",
      "[[[-4. -3. -2.]\n",
      "  [-1.  0.  1.]\n",
      "  [ 2.  3.  4.]]\n",
      "\n",
      " [[-4. -3. -2.]\n",
      "  [-1.  0.  1.]\n",
      "  [ 2.  3.  4.]]]\n",
      "[[[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [2. 3. 4.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 1.]\n",
      "  [2. 3. 4.]]]\n"
     ]
    }
   ],
   "source": [
    "# test activation layer\n",
    "a = np.zeros((2, 3, 3))\n",
    "index = -4\n",
    "for i in range(0,a.shape[1]):\n",
    "    for ii in range(0,a.shape[2]):\n",
    "        a[:, i, ii] = index\n",
    "        index += 1\n",
    "print(\"input before activation\")\n",
    "print(a)\n",
    "r = activation_layer(a.shape)\n",
    "b = r.forward(a)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fully_connected_layer:\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "        w_dim = 1\n",
    "        for d in in_dim:\n",
    "            w_dim = w_dim * d\n",
    "        self.weights = np.ones((self.out_dim, w_dim))\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out_vec = np.zeros(self.out_dim)\n",
    "        img_vec = img.flatten()\n",
    "\n",
    "        for i in range(0, self.out_dim):\n",
    "            out_vec[i] = np.sum(img_vec * self.weights[i])\n",
    "        return out_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input before fully connected\n",
      "[[[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1.]\n",
      "  [1. 1. 1.]\n",
      "  [1. 1. 1.]]]\n",
      "output pool\n",
      "[18. 18. 18.]\n"
     ]
    }
   ],
   "source": [
    "# test fully connected layer\n",
    "a = np.ones((2, 3, 3))\n",
    "\n",
    "print(\"input before fully connected\")\n",
    "print(a)\n",
    "c = fully_connected_layer(in_dim=a.shape, out_dim=3)\n",
    "d = c.forward(a)\n",
    "print(\"output pool\")\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before cnn\n",
      "[[ 0.  1.  2.  3.  4.  5.]\n",
      " [ 6.  7.  8.  9. 10. 11.]\n",
      " [12. 13. 14. 15. 16. 17.]\n",
      " [18. 19. 20. 21. 22. 23.]\n",
      " [24. 25. 26. 27. 28. 29.]\n",
      " [30. 31. 32. 33. 34. 35.]]\n",
      "after conv\n",
      "[[[9.145300e+05 1.007242e+06 1.099954e+06 1.192666e+06]\n",
      "  [1.470802e+06 1.563514e+06 1.656226e+06 1.748938e+06]\n",
      "  [2.027074e+06 2.119786e+06 2.212498e+06 2.305210e+06]\n",
      "  [2.583346e+06 2.676058e+06 2.768770e+06 2.861482e+06]]\n",
      "\n",
      " [[1.320000e+03 1.482000e+03 1.644000e+03 1.806000e+03]\n",
      "  [2.292000e+03 2.454000e+03 2.616000e+03 2.778000e+03]\n",
      "  [3.264000e+03 3.426000e+03 3.588000e+03 3.750000e+03]\n",
      "  [4.236000e+03 4.398000e+03 4.560000e+03 4.722000e+03]]]\n",
      "after activation\n",
      "[[[9.145300e+05 1.007242e+06 1.099954e+06 1.192666e+06]\n",
      "  [1.470802e+06 1.563514e+06 1.656226e+06 1.748938e+06]\n",
      "  [2.027074e+06 2.119786e+06 2.212498e+06 2.305210e+06]\n",
      "  [2.583346e+06 2.676058e+06 2.768770e+06 2.861482e+06]]\n",
      "\n",
      " [[1.320000e+03 1.482000e+03 1.644000e+03 1.806000e+03]\n",
      "  [2.292000e+03 2.454000e+03 2.616000e+03 2.778000e+03]\n",
      "  [3.264000e+03 3.426000e+03 3.588000e+03 3.750000e+03]\n",
      "  [4.236000e+03 4.398000e+03 4.560000e+03 4.722000e+03]]]\n",
      "after pooling\n",
      "[[[2212498. 2305210.]\n",
      "  [2768770. 2861482.]]\n",
      "\n",
      " [[   3588.    3750.]\n",
      "  [   4560.    4722.]]]\n",
      "after fully connected\n",
      "[10164580. 10164580.]\n"
     ]
    }
   ],
   "source": [
    "# test them in succession\n",
    "\n",
    "img = np.ones((6, 6))\n",
    "index = 0\n",
    "for i in range(0,img.shape[0]):\n",
    "    for ii in range(0,img.shape[1]):\n",
    "        img[i, ii] = index\n",
    "        index += 1\n",
    "\n",
    "c1 = conv_layer(in_dim=img.shape, conv_size=(3,3), conv_num=2)\n",
    "a1 = activation_layer(in_dim=c1.get_out_dim())\n",
    "p1 = max_pooling_layer(in_dim=c1.get_out_dim(), pooling_size=(3,3))\n",
    "f1 = fully_connected_layer(in_dim=p1.get_out_dim(), out_dim=2)\n",
    "print(\"before cnn\")\n",
    "print(img)\n",
    "i = c1.forward(img)\n",
    "print(\"after conv\")\n",
    "print(i)\n",
    "i = a1.forward(i)\n",
    "print(\"after activation\")\n",
    "print(i)\n",
    "i = p1.forward(i)\n",
    "print(\"after pooling\")\n",
    "print(i)\n",
    "i = f1.forward(i)\n",
    "print(\"after fully connected\")\n",
    "print(i)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ICDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
